{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2dc01cc",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "\n",
    "A custom wrapper around GloVe embeddings for teaching/demo purposes, loosely modeled after `gensim`'s \n",
    "functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28be11f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d4e648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbeddings:\n",
    "    \n",
    "    vocab = []\n",
    "    vectors = []\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.split()\n",
    "                word, vec = line[0], np.array([float(val) for val in line[1:]])\n",
    "                self.vocab.append(word)\n",
    "                self.vectors.append(vec)\n",
    "        self.vectors = np.array(self.vectors)\n",
    "        \n",
    "    @property\n",
    "    def n_features(self):\n",
    "        return self.vectors.shape[1]\n",
    "    \n",
    "    @property\n",
    "    def idx_word_mapping(self):\n",
    "        return {idx: word for idx, word in enumerate(self.vocab)}\n",
    "    \n",
    "    @property\n",
    "    def word_idx_mapping(self):\n",
    "        return {word: idx for idx, word in enumerate(self.vocab)}\n",
    "        \n",
    "    def vector(self, input_):        \n",
    "        if isinstance(input_, str):\n",
    "            if input_ in self.vocab:\n",
    "                idx = self.word_idx_mapping[input_]\n",
    "                return self.vectors[idx]\n",
    "            else:\n",
    "                raise Exception(f\"{input_} is not in the vocabulary.\")\n",
    "        elif isinstance(input_, list):\n",
    "            vec_list = []\n",
    "            for entry in input_:\n",
    "                if entry in self.vocab:\n",
    "                    idx = self.word_idx_mapping[entry]\n",
    "                    vec_list.append(self.vectors[idx])\n",
    "                else:\n",
    "                    raise Exception(f\"{entry} is not in the vocabulary.\")\n",
    "            return vec_list\n",
    "        else:\n",
    "            raise Exception(\"Only strings or lists allowed.\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def cos_sim(a, b):\n",
    "        dot = np.dot(a, b)\n",
    "        a_norm, b_norm = np.linalg.norm(a), np.linalg.norm(b)\n",
    "        score = dot / np.dot(a_norm, b_norm)\n",
    "        return (score - -1) / (1 - -1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_distance(embeddings, vec):\n",
    "        return np.linalg.norm(embeddings - vec, axis=1)\n",
    "    \n",
    "    def nearest_neighbors(self, input_, k=5, score_type='cosine', raw=False):\n",
    "        if raw is False:\n",
    "            input_ = self.vector(input_)\n",
    "        distances = self.calculate_distance(self.vectors, input_)\n",
    "        sorted_distances = distances.argsort()[:k]\n",
    "        words = [self.idx_word_mapping[idx] for idx in sorted_distances]\n",
    "        if score_type is 'cosine':\n",
    "            scores = [self.cos_sim(input_, self.vector(word)) for word in words]\n",
    "            result = [(word, val) for word, val in zip(words, scores)]\n",
    "            return sorted(result, key=lambda tup: tup[1], reverse=True)\n",
    "        elif score_type is 'distance':\n",
    "            scores = distances[sorted_distances]\n",
    "            result = [(word, val) for word, val in zip(words, scores)]\n",
    "            return sorted(result, key=lambda tup: tup[1])\n",
    "        else:\n",
    "            raise Exception(\"Score type not available, use `cosine` or `distance`.\")\n",
    "            \n",
    "    def most_distant(self, input_, k=5, score_type='cosine', raw=False):\n",
    "        if raw is False:\n",
    "            input_ = self.vector(input_)\n",
    "        distances = self.calculate_distance(self.vectors, input_)\n",
    "        sorted_distances = distances.argsort()[-k:]\n",
    "        words = [self.idx_word_mapping[idx] for idx in sorted_distances]\n",
    "        if score_type is 'cosine':\n",
    "            scores = [self.cos_sim(input_, self.vector(word)) for word in words]\n",
    "            result = [(word, val) for word, val in zip(words, scores)]\n",
    "            return sorted(result, key=lambda tup: tup[1])\n",
    "        elif score_type is 'distance':\n",
    "            scores = distances[sorted_distances]\n",
    "            result = [(word, val) for word, val in zip(words, scores)]\n",
    "            return sorted(result, key=lambda tup: tup[1], reverse=True)\n",
    "        else:\n",
    "            raise Exception(\"Score type not available, use `cosine` or `distance`.\")\n",
    "            \n",
    "    def analogize(self, source: list, target: str, k=5, score_type='cosine'):\n",
    "        source, target = self.vector(source), self.vector(target)\n",
    "        vec = target - source[0] + source[1]\n",
    "        return self.nearest_neighbors(vec, k=k, score_type=score_type, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a54b9841",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = WordEmbeddings(\"data/glove/glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a5982eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('italy', 0.9154047999085728),\n",
       " ('rome', 0.9092034423709726),\n",
       " ('milan', 0.8952465727474838),\n",
       " ('genoa', 0.8874150491232438),\n",
       " ('naples', 0.8799018070278701)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.analogize(['uk', 'london'], 'italy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a658750c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
